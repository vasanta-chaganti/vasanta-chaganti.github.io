---
permalink: /research/
title: "Research"
author_profile: true
redirect_from: 
  - /research.html
---

## Research Projects


### Project 1: Latency to Where? Measures of Network Performance Using Open Source SpeedTest Measurements
> ![Latency](/images/Latency.png){:height="400px" width="400px"}
>
Our work investigates the impact of network latency, utilizing open-source latency measurements. We uncover limitations and inconsistencies in the various measurement methods, and point out barriers to accurate data collection. Our work is in collaboration with MIT, and funded through a Comcast Innovation Fund. 
> 
> 

### Project 2: A View From Above: Starlink Performance Across the Globe
> ![Starlink](/images/starlink-wikimedia.jpg){:height="400px" width="400px"}
> 
Our research compares the performance of Starlink with traditional broadband and wireless networks. Our results indicate that while Starlink offers competitive latency and download speeds, broadband networks provide more consistent performance in urban areas. Wireless networks, on the other hand, show significant variability depending on location and network congestion.
> <sub>Image Source: Wikimedia Commons</sub>


### Project 3: Differential Privacy Applied to Large Scale Network Traffic Analysis
> ![DP-Networks](/images/DP-Networks.png){:height="500px" width="500px"}
> 
We work in collaboration with Akamai, a large content distribution network, to  privately identifying distinct classes of network use, to release open-source measurements, that have high-utility over network queries over last-mile ISP and Edge service providers, while preserving  anonymity of individual ISPs. 
> 

### Project 4: Designing Differentially-Private Algorithms for Mobile User Trajectories
> ![DP-Trajectories](/images/DP-Trajectory.png){:height="500px" width="500px"}
>
In this work we develop DP-GANs (Differentially Private Generative Adversarial Networks) to model fine-grained synthetic network traces, that preserve micro-statistics, while protecting end-user privacy with stringent privacy budgets. We find ML models to be a natural fit with Differential Privacy – the “noise” introduced through DP helps prevent ML models from over-fitting while also protecting end-user data. 
>
> 

